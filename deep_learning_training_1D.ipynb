{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "975dd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "651a94f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_index</th>\n",
       "      <th>time</th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_V</th>\n",
       "      <th>str_s</th>\n",
       "      <th>str_d</th>\n",
       "      <th>str</th>\n",
       "      <th>Wsto</th>\n",
       "      <th>Wdis</th>\n",
       "      <th>Wtotal</th>\n",
       "      <th>Esto</th>\n",
       "      <th>Edis</th>\n",
       "      <th>Etotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>-0.004951</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.402922e-07</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.402922e-07</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>9.424147e-07</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.182707e-06</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.014419</td>\n",
       "      <td>-0.014710</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2.079196e-06</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3.261903e-06</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>-0.019519</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>3.624699e-06</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>6.886602e-06</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>2.091395e-05</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>2.117821e-03</td>\n",
       "      <td>0.003199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>0.049737</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.473773e-05</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>2.142558e-03</td>\n",
       "      <td>0.003273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>0.053664</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>2.879799e-05</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>2.171356e-03</td>\n",
       "      <td>0.003370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>0.057513</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>3.307802e-05</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>2.204434e-03</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>0.028144</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>3.756187e-05</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>2.241996e-03</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    load_index  time    eps     eps_V     str_s     str_d       str      Wsto  \\\n",
       "0          0.0   0.0  0.000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1          0.0   1.0 -0.005 -0.000049 -0.000049 -0.004902 -0.004951  0.000025   \n",
       "2          0.0   2.0 -0.010 -0.000146 -0.000146 -0.009708 -0.009854  0.000048   \n",
       "3          0.0   3.0 -0.015 -0.000290 -0.000290 -0.014419 -0.014710  0.000071   \n",
       "4          0.0   4.0 -0.020 -0.000481 -0.000481 -0.019039 -0.019519  0.000094   \n",
       "..         ...   ...    ...       ...       ...       ...       ...       ...   \n",
       "95         0.0  95.0 -0.025 -0.035366 -0.035366  0.045732  0.010366  0.000031   \n",
       "96         0.0  96.0 -0.020 -0.034869 -0.034869  0.049737  0.014869  0.000050   \n",
       "97         0.0  97.0 -0.015 -0.034332 -0.034332  0.053664  0.019332  0.000068   \n",
       "98         0.0  98.0 -0.010 -0.033757 -0.033757  0.057513  0.023757  0.000086   \n",
       "99         0.0  99.0 -0.005 -0.033144 -0.033144  0.061288  0.028144  0.000103   \n",
       "\n",
       "            Wdis    Wtotal      Esto          Edis    Etotal  \n",
       "0   0.000000e+00  0.000000  0.000000  0.000000e+00  0.000000  \n",
       "1   2.402922e-07  0.000025  0.000025  2.402922e-07  0.000025  \n",
       "2   9.424147e-07  0.000049  0.000073  1.182707e-06  0.000074  \n",
       "3   2.079196e-06  0.000074  0.000144  3.261903e-06  0.000148  \n",
       "4   3.624699e-06  0.000098  0.000238  6.886602e-06  0.000245  \n",
       "..           ...       ...       ...           ...       ...  \n",
       "95  2.091395e-05  0.000052  0.001081  2.117821e-03  0.003199  \n",
       "96  2.473773e-05  0.000074  0.001131  2.142558e-03  0.003273  \n",
       "97  2.879799e-05  0.000097  0.001199  2.171356e-03  0.003370  \n",
       "98  3.307802e-05  0.000119  0.001284  2.204434e-03  0.003489  \n",
       "99  3.756187e-05  0.000141  0.001388  2.241996e-03  0.003630  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.dat\")\n",
    "dataset = data.copy()\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77191f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the relevant variables for training\n",
    "#eps = total strain at present\n",
    "#eps_n1 = total strain at present timestep +1 (future)\n",
    "#eps_V = viscous strain at present\n",
    "#eps_V-n1 = viscous strain at future\n",
    "#str_n1 = total stress at future\n",
    "\n",
    "df = np.zeros((len(dataset)-1,5))\n",
    "df[:,0] = dataset.iloc[:-1,2]\n",
    "df[:,1] = dataset.iloc[1:,2]\n",
    "df[:,2] = dataset.iloc[:-1,3]\n",
    "df[:,3] = dataset.iloc[1:,3]\n",
    "df[:,4] = dataset.iloc[1:,6]\n",
    "df = pd.DataFrame(df, columns=[\"eps\", \"eps_n1\", \"eps_V\", \"eps_V_n1\", \"str_n1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd38683f-136a-4131-b5c7-b705770a3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in our database: 1478740\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows in our database: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7f65b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only select 10.000 rows to limit the trianing procedure (know your problem)\n",
    "num_data = 10000\n",
    "x = df.iloc[:num_data, :3] #input: present total strain, future total strain, and present viscous strain\n",
    "y = df.iloc[:num_data, 3:] #predict: future viscous strain and future total stress\n",
    "\n",
    "my_scaler = StandardScaler() #apply scaler\n",
    "x = my_scaler.fit_transform(x)#x.to_numpy().reshape(-1,1)) #use the commented reshape if you want to train RNN \n",
    "y = my_scaler.fit_transform(y)#y.to_numpy().reshape(-1,1)) #use the commented reshape if you want to train RNN\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb762bb7-a84a-45df-9a40-fb5bed8b0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us tune the hyperparameters our our deep learning model\n",
    "#We arbitrarily choose 3 middle layers which number of neurons and activation functions are optimised\n",
    "#We also optimise the learning rate then compile the model and later we will save the best hyperparameters\n",
    "#This is for the feed forward neural network algorithm (FFNN)\n",
    "def model_builder(hp):\n",
    "    inputs = keras.Input(shape=(x_train.shape[1], 3))\n",
    "    hp_units_1 = hp.Int(\"units_1\", min_value=4, max_value=256, step=16)\n",
    "    hp_units_2 = hp.Int(\"units_2\", min_value=4, max_value=256, step=16)\n",
    "    hp_units_3 = hp.Int(\"units_3\", min_value=4, max_value=256, step=16)\n",
    "\n",
    "    hp_activation_1 = hp.Choice(\"activation_1\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    hp_activation_2 = hp.Choice(\"activation_2\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    hp_activation_3 = hp.Choice(\"activation_3\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    v = layers.Dense(units=hp_units_1, activation=hp_activation_1, use_bias=True)(inputs)\n",
    "    v = layers.Dense(units=hp_units_2, activation=hp_activation_2, use_bias=True)(v)\n",
    "    v = layers.Dense(units=hp_units_3, activation=hp_activation_3, use_bias=True)(v)\n",
    "\n",
    "    outputs = layers.Dense(2)(v)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"model_FFNN_tuning\")\n",
    "    \n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "                  loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0492ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 12s]\n",
      "mean_squared_error: 0.01119103655219078\n",
      "\n",
      "Best mean_squared_error So Far: 0.010301079601049423\n",
      "Total elapsed time: 00h 05m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#Implementation of the hyperparameters optimisation\n",
    "#Please note that this may take a while to run, depends on your computing power\n",
    "import os\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = \"mean_squared_error\",\n",
    "                     max_epochs = 50,\n",
    "                     factor = 3,\n",
    "                     directory = r\"./my_dir\",\n",
    "                     project_name = \"1D_visco_FFNN\",\n",
    "                     overwrite=True,\n",
    "                    )\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x_train, y_train, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "487066e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x0000026661C0D888>\n",
      "84\n",
      "84\n",
      "164\n",
      "0.001\n",
      "relu\n",
      "relu\n",
      "relu\n"
     ]
    }
   ],
   "source": [
    "#Printing out the optimised hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)\n",
    "print(best_hps.get(\"units_1\"))\n",
    "print(best_hps.get(\"units_2\"))\n",
    "print(best_hps.get(\"units_3\"))\n",
    "print(best_hps.get(\"learning_rate\"))\n",
    "\n",
    "print(best_hps.get(\"activation_1\"))\n",
    "print(best_hps.get(\"activation_2\"))\n",
    "print(best_hps.get(\"activation_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a935a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 3), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (20, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 3), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (20, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 3), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "Test Loss: 0.015282166190445423\n",
      "Test Accuracy 0.9894999861717224\n"
     ]
    }
   ],
   "source": [
    "#Create the layers\n",
    "inputs = keras.Input(shape=(x_train.shape[1], 3))\n",
    "x = layers.Dense(best_hps.get(\"units_1\"), activation=best_hps.get(\"activation_1\"))(inputs)\n",
    "x = layers.Dense(best_hps.get(\"units_2\"), activation=best_hps.get(\"activation_2\"))(x)\n",
    "x = layers.Dense(best_hps.get(\"units_3\"), activation=best_hps.get(\"activation_3\"))(x)\n",
    "outputs = layers.Dense(2)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"model\")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_hps.get(\"learning_rate\")), \n",
    "                  loss=\"mse\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Test Accuracy\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63be9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 717us/step - loss: 0.0160 - accuracy: 0.9810\n",
      "Test Loss: 0.016011305153369904\n",
      "Test Accuracy 0.9810000061988831\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Test Accuracy\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7cd95-7526-45f7-b777-dd53c68599df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us tune the hyperparameters our our deep learning model\n",
    "#We arbitrarily choose 3 middle layers which number of neurons and activation functions are optimised\n",
    "#We also optimise the learning rate then compile the model and later we will save the best hyperparameters\n",
    "#This is for RNN (recurrent neural network) algorithm, we do not use, please modify the input file so that the dimensions match\n",
    "#def model_builder(hp):\n",
    "#    inputs = keras.Input(shape=(x_train.shape[1], 1))\n",
    "#    hp_units_1 = hp.Int(\"units_1\", min_value=4, max_value=256, step=16)\n",
    "#    hp_units_2 = hp.Int(\"units_2\", min_value=4, max_value=256, step=16)\n",
    "#    hp_units_3 = hp.Int(\"units_3\", min_value=4, max_value=256, step=16)\n",
    "#\n",
    "#    hp_activation_1 = hp.Choice(\"activation_1\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "#    hp_activation_2 = hp.Choice(\"activation_2\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "#    hp_activation_3 = hp.Choice(\"activation_3\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "#    \n",
    "#    v = layers.LSTM(units=hp_units_1, activation=hp_activation_1, return_sequences = True, use_bias=True)(inputs)\n",
    "#    v = layers.LSTM(units=hp_units_2, activation=hp_activation_2, return_sequences = True, use_bias=True)(v)\n",
    "#    v = layers.LSTM(units=hp_units_3, activation=hp_activation_3, return_sequences = True, use_bias=True)(v)\n",
    "#    \n",
    "#outputs = layers.TimeDistributed(layers.Dense(1))(v) We do not use RNN, however this can be changed\n",
    "#    model = keras.Model(inputs=inputs, outputs=outputs, name=\"model_RNN_tuning\")\n",
    "#    \n",
    "#    hp_learning_rate = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
    "#    \n",
    "#    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "#                  loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483acbf-3e57-46e9-b152-a17c050efd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(x_train.shape[1], 1))\n",
    "v = layers.LSTM(units = 32, return_sequences = True, activation=\"relu\", use_bias=True)(inputs)\n",
    "v = layers.LSTM(units = 32, return_sequences = True, activation=\"relu\", use_bias=True)(v)\n",
    "v = layers.LSTM(units = 32, return_sequences = True)(v)\n",
    "outputs = layers.TimeDistributed(layers.Dense(1))(v)\n",
    "\n",
    "model_RNN = keras.Model(inputs=inputs, outputs=outputs, name=\"model_RNN\")\n",
    "model_RNN.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
