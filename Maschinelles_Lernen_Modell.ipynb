{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975dd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651a94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836f1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68adb5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_index</th>\n",
       "      <th>time</th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_V</th>\n",
       "      <th>str_s</th>\n",
       "      <th>str_d</th>\n",
       "      <th>str</th>\n",
       "      <th>Wsto</th>\n",
       "      <th>Wdis</th>\n",
       "      <th>Wtotal</th>\n",
       "      <th>Esto</th>\n",
       "      <th>Edis</th>\n",
       "      <th>Etotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>-0.004951</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.402922e-07</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.402922e-07</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>9.424147e-07</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.182707e-06</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.014419</td>\n",
       "      <td>-0.014710</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2.079196e-06</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3.261903e-06</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>-0.019519</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>3.624699e-06</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>6.886602e-06</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>2.091395e-05</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>2.117821e-03</td>\n",
       "      <td>0.003199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>0.049737</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.473773e-05</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>2.142558e-03</td>\n",
       "      <td>0.003273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>0.053664</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>2.879799e-05</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>2.171356e-03</td>\n",
       "      <td>0.003370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>0.057513</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>3.307802e-05</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>2.204434e-03</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>0.028144</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>3.756187e-05</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>2.241996e-03</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    load_index  time    eps     eps_V     str_s     str_d       str      Wsto  \\\n",
       "0          0.0   0.0  0.000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1          0.0   1.0 -0.005 -0.000049 -0.000049 -0.004902 -0.004951  0.000025   \n",
       "2          0.0   2.0 -0.010 -0.000146 -0.000146 -0.009708 -0.009854  0.000048   \n",
       "3          0.0   3.0 -0.015 -0.000290 -0.000290 -0.014419 -0.014710  0.000071   \n",
       "4          0.0   4.0 -0.020 -0.000481 -0.000481 -0.019039 -0.019519  0.000094   \n",
       "..         ...   ...    ...       ...       ...       ...       ...       ...   \n",
       "95         0.0  95.0 -0.025 -0.035366 -0.035366  0.045732  0.010366  0.000031   \n",
       "96         0.0  96.0 -0.020 -0.034869 -0.034869  0.049737  0.014869  0.000050   \n",
       "97         0.0  97.0 -0.015 -0.034332 -0.034332  0.053664  0.019332  0.000068   \n",
       "98         0.0  98.0 -0.010 -0.033757 -0.033757  0.057513  0.023757  0.000086   \n",
       "99         0.0  99.0 -0.005 -0.033144 -0.033144  0.061288  0.028144  0.000103   \n",
       "\n",
       "            Wdis    Wtotal      Esto          Edis    Etotal  \n",
       "0   0.000000e+00  0.000000  0.000000  0.000000e+00  0.000000  \n",
       "1   2.402922e-07  0.000025  0.000025  2.402922e-07  0.000025  \n",
       "2   9.424147e-07  0.000049  0.000073  1.182707e-06  0.000074  \n",
       "3   2.079196e-06  0.000074  0.000144  3.261903e-06  0.000148  \n",
       "4   3.624699e-06  0.000098  0.000238  6.886602e-06  0.000245  \n",
       "..           ...       ...       ...           ...       ...  \n",
       "95  2.091395e-05  0.000052  0.001081  2.117821e-03  0.003199  \n",
       "96  2.473773e-05  0.000074  0.001131  2.142558e-03  0.003273  \n",
       "97  2.879799e-05  0.000097  0.001199  2.171356e-03  0.003370  \n",
       "98  3.307802e-05  0.000119  0.001284  2.204434e-03  0.003489  \n",
       "99  3.756187e-05  0.000141  0.001388  2.241996e-03  0.003630  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77191f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.zeros((len(dataset)-1,5))\n",
    "df[:,0] = dataset.iloc[:-1,2]\n",
    "df[:,1] = dataset.iloc[1:,2]\n",
    "df[:,2] = dataset.iloc[:-1,3]\n",
    "df[:,3] = dataset.iloc[1:,3]\n",
    "df[:,4] = dataset.iloc[1:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55b96ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_n1</th>\n",
       "      <th>eps_V</th>\n",
       "      <th>eps_V_n1</th>\n",
       "      <th>str_n1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.027432</td>\n",
       "      <td>-0.027875</td>\n",
       "      <td>-0.072125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.027875</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>-0.071692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.028308</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>-0.071266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>-0.029151</td>\n",
       "      <td>-0.070849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.029151</td>\n",
       "      <td>-0.029560</td>\n",
       "      <td>-0.070440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.029560</td>\n",
       "      <td>-0.029960</td>\n",
       "      <td>-0.070040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.029960</td>\n",
       "      <td>-0.030353</td>\n",
       "      <td>-0.069647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.030353</td>\n",
       "      <td>-0.030739</td>\n",
       "      <td>-0.069261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.030739</td>\n",
       "      <td>-0.031116</td>\n",
       "      <td>-0.068884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.031116</td>\n",
       "      <td>-0.031486</td>\n",
       "      <td>-0.068514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.031486</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>-0.068151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>-0.032205</td>\n",
       "      <td>-0.067795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.032205</td>\n",
       "      <td>-0.032554</td>\n",
       "      <td>-0.067446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.032554</td>\n",
       "      <td>-0.032896</td>\n",
       "      <td>-0.067104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.032896</td>\n",
       "      <td>-0.033232</td>\n",
       "      <td>-0.066768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.033232</td>\n",
       "      <td>-0.033561</td>\n",
       "      <td>-0.066439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.033561</td>\n",
       "      <td>-0.033883</td>\n",
       "      <td>-0.066117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.033883</td>\n",
       "      <td>-0.034199</td>\n",
       "      <td>-0.065801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.034199</td>\n",
       "      <td>-0.034509</td>\n",
       "      <td>-0.065491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.034509</td>\n",
       "      <td>-0.034812</td>\n",
       "      <td>-0.065188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.034812</td>\n",
       "      <td>-0.035110</td>\n",
       "      <td>-0.064890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.035110</td>\n",
       "      <td>-0.035402</td>\n",
       "      <td>-0.064598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.035402</td>\n",
       "      <td>-0.035688</td>\n",
       "      <td>-0.064312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.035688</td>\n",
       "      <td>-0.035969</td>\n",
       "      <td>-0.064031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.035969</td>\n",
       "      <td>-0.036244</td>\n",
       "      <td>-0.063756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.036244</td>\n",
       "      <td>-0.036514</td>\n",
       "      <td>-0.063486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.036514</td>\n",
       "      <td>-0.036778</td>\n",
       "      <td>-0.063222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.036778</td>\n",
       "      <td>-0.037038</td>\n",
       "      <td>-0.062962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.037038</td>\n",
       "      <td>-0.037292</td>\n",
       "      <td>-0.062708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>-0.037292</td>\n",
       "      <td>-0.037541</td>\n",
       "      <td>-0.062459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>-9.500000e-02</td>\n",
       "      <td>-0.037541</td>\n",
       "      <td>-0.037736</td>\n",
       "      <td>-0.057264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.095</td>\n",
       "      <td>-9.000000e-02</td>\n",
       "      <td>-0.037736</td>\n",
       "      <td>-0.037879</td>\n",
       "      <td>-0.052121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.090</td>\n",
       "      <td>-8.500000e-02</td>\n",
       "      <td>-0.037879</td>\n",
       "      <td>-0.037969</td>\n",
       "      <td>-0.047031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.085</td>\n",
       "      <td>-8.000000e-02</td>\n",
       "      <td>-0.037969</td>\n",
       "      <td>-0.038009</td>\n",
       "      <td>-0.041991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>-7.500000e-02</td>\n",
       "      <td>-0.038009</td>\n",
       "      <td>-0.037999</td>\n",
       "      <td>-0.037001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.075</td>\n",
       "      <td>-7.000000e-02</td>\n",
       "      <td>-0.037999</td>\n",
       "      <td>-0.037940</td>\n",
       "      <td>-0.032060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.070</td>\n",
       "      <td>-6.500000e-02</td>\n",
       "      <td>-0.037940</td>\n",
       "      <td>-0.037834</td>\n",
       "      <td>-0.027166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.065</td>\n",
       "      <td>-6.000000e-02</td>\n",
       "      <td>-0.037834</td>\n",
       "      <td>-0.037680</td>\n",
       "      <td>-0.022320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-5.500000e-02</td>\n",
       "      <td>-0.037680</td>\n",
       "      <td>-0.037480</td>\n",
       "      <td>-0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.055</td>\n",
       "      <td>-5.000000e-02</td>\n",
       "      <td>-0.037480</td>\n",
       "      <td>-0.037236</td>\n",
       "      <td>-0.012764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>-4.500000e-02</td>\n",
       "      <td>-0.037236</td>\n",
       "      <td>-0.036947</td>\n",
       "      <td>-0.008053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-4.000000e-02</td>\n",
       "      <td>-0.036947</td>\n",
       "      <td>-0.036614</td>\n",
       "      <td>-0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.040</td>\n",
       "      <td>-3.500000e-02</td>\n",
       "      <td>-0.036614</td>\n",
       "      <td>-0.036240</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-3.000000e-02</td>\n",
       "      <td>-0.036240</td>\n",
       "      <td>-0.035823</td>\n",
       "      <td>0.005823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-2.500000e-02</td>\n",
       "      <td>-0.035823</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>0.010366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.025</td>\n",
       "      <td>-2.000000e-02</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>0.014869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.020</td>\n",
       "      <td>-1.500000e-02</td>\n",
       "      <td>-0.034869</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>0.019332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.015</td>\n",
       "      <td>-1.000000e-02</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>0.023757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>-5.000000e-03</td>\n",
       "      <td>-0.033757</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>0.028144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>1.734723e-18</td>\n",
       "      <td>-0.033144</td>\n",
       "      <td>-0.032494</td>\n",
       "      <td>0.032494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eps        eps_n1     eps_V  eps_V_n1    str_n1\n",
       "50 -0.100 -1.000000e-01 -0.027432 -0.027875 -0.072125\n",
       "51 -0.100 -1.000000e-01 -0.027875 -0.028308 -0.071692\n",
       "52 -0.100 -1.000000e-01 -0.028308 -0.028734 -0.071266\n",
       "53 -0.100 -1.000000e-01 -0.028734 -0.029151 -0.070849\n",
       "54 -0.100 -1.000000e-01 -0.029151 -0.029560 -0.070440\n",
       "55 -0.100 -1.000000e-01 -0.029560 -0.029960 -0.070040\n",
       "56 -0.100 -1.000000e-01 -0.029960 -0.030353 -0.069647\n",
       "57 -0.100 -1.000000e-01 -0.030353 -0.030739 -0.069261\n",
       "58 -0.100 -1.000000e-01 -0.030739 -0.031116 -0.068884\n",
       "59 -0.100 -1.000000e-01 -0.031116 -0.031486 -0.068514\n",
       "60 -0.100 -1.000000e-01 -0.031486 -0.031849 -0.068151\n",
       "61 -0.100 -1.000000e-01 -0.031849 -0.032205 -0.067795\n",
       "62 -0.100 -1.000000e-01 -0.032205 -0.032554 -0.067446\n",
       "63 -0.100 -1.000000e-01 -0.032554 -0.032896 -0.067104\n",
       "64 -0.100 -1.000000e-01 -0.032896 -0.033232 -0.066768\n",
       "65 -0.100 -1.000000e-01 -0.033232 -0.033561 -0.066439\n",
       "66 -0.100 -1.000000e-01 -0.033561 -0.033883 -0.066117\n",
       "67 -0.100 -1.000000e-01 -0.033883 -0.034199 -0.065801\n",
       "68 -0.100 -1.000000e-01 -0.034199 -0.034509 -0.065491\n",
       "69 -0.100 -1.000000e-01 -0.034509 -0.034812 -0.065188\n",
       "70 -0.100 -1.000000e-01 -0.034812 -0.035110 -0.064890\n",
       "71 -0.100 -1.000000e-01 -0.035110 -0.035402 -0.064598\n",
       "72 -0.100 -1.000000e-01 -0.035402 -0.035688 -0.064312\n",
       "73 -0.100 -1.000000e-01 -0.035688 -0.035969 -0.064031\n",
       "74 -0.100 -1.000000e-01 -0.035969 -0.036244 -0.063756\n",
       "75 -0.100 -1.000000e-01 -0.036244 -0.036514 -0.063486\n",
       "76 -0.100 -1.000000e-01 -0.036514 -0.036778 -0.063222\n",
       "77 -0.100 -1.000000e-01 -0.036778 -0.037038 -0.062962\n",
       "78 -0.100 -1.000000e-01 -0.037038 -0.037292 -0.062708\n",
       "79 -0.100 -1.000000e-01 -0.037292 -0.037541 -0.062459\n",
       "80 -0.100 -9.500000e-02 -0.037541 -0.037736 -0.057264\n",
       "81 -0.095 -9.000000e-02 -0.037736 -0.037879 -0.052121\n",
       "82 -0.090 -8.500000e-02 -0.037879 -0.037969 -0.047031\n",
       "83 -0.085 -8.000000e-02 -0.037969 -0.038009 -0.041991\n",
       "84 -0.080 -7.500000e-02 -0.038009 -0.037999 -0.037001\n",
       "85 -0.075 -7.000000e-02 -0.037999 -0.037940 -0.032060\n",
       "86 -0.070 -6.500000e-02 -0.037940 -0.037834 -0.027166\n",
       "87 -0.065 -6.000000e-02 -0.037834 -0.037680 -0.022320\n",
       "88 -0.060 -5.500000e-02 -0.037680 -0.037480 -0.017520\n",
       "89 -0.055 -5.000000e-02 -0.037480 -0.037236 -0.012764\n",
       "90 -0.050 -4.500000e-02 -0.037236 -0.036947 -0.008053\n",
       "91 -0.045 -4.000000e-02 -0.036947 -0.036614 -0.003386\n",
       "92 -0.040 -3.500000e-02 -0.036614 -0.036240  0.001240\n",
       "93 -0.035 -3.000000e-02 -0.036240 -0.035823  0.005823\n",
       "94 -0.030 -2.500000e-02 -0.035823 -0.035366  0.010366\n",
       "95 -0.025 -2.000000e-02 -0.035366 -0.034869  0.014869\n",
       "96 -0.020 -1.500000e-02 -0.034869 -0.034332  0.019332\n",
       "97 -0.015 -1.000000e-02 -0.034332 -0.033757  0.023757\n",
       "98 -0.010 -5.000000e-03 -0.033757 -0.033144  0.028144\n",
       "99 -0.005  1.734723e-18 -0.033144 -0.032494  0.032494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df, columns=[\"eps\", \"eps_n1\", \"eps_V\", \"eps_V_n1\", \"str_n1\"])\n",
    "df.iloc[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f65b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_data = 10000\n",
    "x = df.iloc[:num_data, 0]\n",
    "y = df.iloc[:num_data, -1]\n",
    "\n",
    "my_scaler = StandardScaler()\n",
    "x = my_scaler.fit_transform(x.to_numpy().reshape(-1,1))\n",
    "y = my_scaler.fit_transform(y.to_numpy().reshape(-1,1))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2f943f-0671-4f15-b429-0433891323d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-82dfd62b4155>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-82dfd62b4155>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    v = layers.LSTM(units = 32, return_sequences = True, activation=\"relu\", use_bias=True)(v)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(x_train.shape[1], 1))\n",
    "v = layers.LSTM(units = 32, return_sequences = True, activation=\"relu\", use_bias=True)(inputs)\n",
    "v = layers.LSTM(units = 32, return_sequences = True, activation=\"relu\", use_bias=True)(v)\n",
    "v = layers.LSTM(units = 32, return_sequences = True)(v)\n",
    "outputs = layers.TimeDistributed(layers.Dense(1))(v)\n",
    "\n",
    "model_RNN = keras.Model(inputs=inputs, outputs=outputs, name=\"model_RNN\")\n",
    "model_RNN.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "582570d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    inputs = keras.Input(shape=(x_train.shape[1], 1))\n",
    "    hp_units_1 = hp.Int(\"units_1\", min_value=4, max_value=256, step=16)\n",
    "    hp_units_2 = hp.Int(\"units_2\", min_value=4, max_value=256, step=16)\n",
    "    hp_units_3 = hp.Int(\"units_3\", min_value=4, max_value=256, step=16)\n",
    "\n",
    "    hp_activation_1 = hp.Choice(\"activation_1\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    hp_activation_2 = hp.Choice(\"activation_2\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    hp_activation_3 = hp.Choice(\"activation_3\", values = [\"tanh\", \"sigmoid\", \"relu\"])\n",
    "    \n",
    "    v = layers.LSTM(units=hp_units_1, activation=hp_activation_1, return_sequences = True, use_bias=True)(inputs)\n",
    "    v = layers.LSTM(units=hp_units_2, activation=hp_activation_2, return_sequences = True, use_bias=True)(v)\n",
    "    v = layers.LSTM(units=hp_units_3, activation=hp_activation_3, return_sequences = True, use_bias=True)(v)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(v)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"model_RNN_tuning\")\n",
    "    \n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "                  loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0492ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 26s]\n",
      "mean_squared_error: 0.06489246338605881\n",
      "\n",
      "Best mean_squared_error So Far: 0.06471633166074753\n",
      "Total elapsed time: 00h 10m 47s\n",
      "\n",
      "Search: Running Trial #51\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units_1           |20                |20                \n",
      "units_2           |36                |36                \n",
      "units_3           |68                |68                \n",
      "activation_1      |tanh              |tanh              \n",
      "activation_2      |relu              |relu              \n",
      "activation_3      |sigmoid           |sigmoid           \n",
      "learning_rate     |0.001             |0.001             \n",
      "tuner/epochs      |50                |17                \n",
      "tuner/initial_e...|17                |6                 \n",
      "tuner/bracket     |3                 |3                 \n",
      "tuner/round       |3                 |2                 \n",
      "tuner/trial_id    |c765474bd38d12d...|8d9d5bfce05d23d...\n",
      "\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 5s 8ms/step - loss: 0.4729 - mean_squared_error: 0.4729 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0689 - mean_squared_error: 0.0689 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: my_dir\\1D_visco_FFNN\\trial_80308e41c7b8f3288e1fa6b56d0e97c8\\checkpoints\\epoch_0\\checkpoint.tmp8ad98a2610714baf80cc958e79cfe23b to: my_dir\\1D_visco_FFNN\\trial_80308e41c7b8f3288e1fa6b56d0e97c8\\checkpoints\\epoch_0\\checkpoint : Toegang geweigerd.\r\n; Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-390b7b4b034b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     )\n\u001b[0;32m     10\u001b[0m \u001b[0mstop_early\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;31m# objective left unspecified,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1418\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 self.model.save_weights(\n\u001b[1;32m-> 1420\u001b[1;33m                     filepath, overwrite=True, options=self._options)\n\u001b[0m\u001b[0;32m   1421\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2262\u001b[0m           \u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m           \u001b[0msave_relative_paths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m           all_model_checkpoint_paths=[filepath])\n\u001b[0m\u001b[0;32m   2265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m   def load_weights(self,\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36mupdate_checkpoint_state_internal\u001b[1;34m(save_dir, model_checkpoint_path, all_model_checkpoint_paths, latest_filename, save_relative_paths, all_model_checkpoint_timestamps, last_preserved_timestamp)\u001b[0m\n\u001b[0;32m    247\u001b[0m   \u001b[1;31m# file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m   file_io.atomic_write_string_to_file(coord_checkpoint_filename,\n\u001b[1;32m--> 249\u001b[1;33m                                       text_format.MessageToString(ckpt))\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[0mwrite_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m       \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m       \u001b[0mdelete_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(oldname, newname, overwrite)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m   \"\"\"\n\u001b[1;32m--> 607\u001b[1;33m   \u001b[0mrename_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moldname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vince\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[1;34m(src, dst, overwrite)\u001b[0m\n\u001b[0;32m    622\u001b[0m   \"\"\"\n\u001b[0;32m    623\u001b[0m   _pywrap_file_io.RenameFile(\n\u001b[1;32m--> 624\u001b[1;33m       compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: my_dir\\1D_visco_FFNN\\trial_80308e41c7b8f3288e1fa6b56d0e97c8\\checkpoints\\epoch_0\\checkpoint.tmp8ad98a2610714baf80cc958e79cfe23b to: my_dir\\1D_visco_FFNN\\trial_80308e41c7b8f3288e1fa6b56d0e97c8\\checkpoints\\epoch_0\\checkpoint : Toegang geweigerd.\r\n; Input/output error"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = \"mean_squared_error\",\n",
    "                     max_epochs = 50,\n",
    "                     factor = 3,\n",
    "                     directory = \"my_dir\",\n",
    "                     project_name = \"1D_visco_FFNN\",\n",
    "                     overwrite=True,\n",
    "                    )\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x_train, y_train, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "487066e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f57444cd220>\n",
      "276\n",
      "212\n",
      "244\n",
      "0.0001\n",
      "tanh\n",
      "tanh\n",
      "tanh\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)\n",
    "print(best_hps.get(\"units_1\"))\n",
    "print(best_hps.get(\"units_2\"))\n",
    "print(best_hps.get(\"units_3\"))\n",
    "print(best_hps.get(\"learning_rate\"))\n",
    "\n",
    "print(best_hps.get(\"activation_1\"))\n",
    "print(best_hps.get(\"activation_2\"))\n",
    "print(best_hps.get(\"activation_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a935a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 1s 808us/step - loss: 0.0098 - accuracy: 0.9222\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 0s 951us/step - loss: 5.6339e-04 - accuracy: 0.9830\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 0s 860us/step - loss: 5.5148e-04 - accuracy: 0.9808\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 0s 885us/step - loss: 5.3958e-04 - accuracy: 0.9831\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 0s 905us/step - loss: 5.2914e-04 - accuracy: 0.9851\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 0s 889us/step - loss: 5.4267e-04 - accuracy: 0.9860\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 0s 821us/step - loss: 5.2825e-04 - accuracy: 0.9855\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 0s 837us/step - loss: 5.0670e-04 - accuracy: 0.9862\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 0s 875us/step - loss: 5.0590e-04 - accuracy: 0.9891\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 5.2483e-04 - accuracy: 0.9877\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 0s 816us/step - loss: 5.1440e-04 - accuracy: 0.9871\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 0s 849us/step - loss: 5.3518e-04 - accuracy: 0.9847\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 0s 808us/step - loss: 5.2186e-04 - accuracy: 0.9852\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 0s 842us/step - loss: 5.1633e-04 - accuracy: 0.9859\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 0s 858us/step - loss: 5.2239e-04 - accuracy: 0.9856\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 0s 798us/step - loss: 5.3873e-04 - accuracy: 0.9850\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 0s 823us/step - loss: 5.1349e-04 - accuracy: 0.9874\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 0s 843us/step - loss: 5.1192e-04 - accuracy: 0.9865\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 0s 811us/step - loss: 5.1076e-04 - accuracy: 0.9843\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 0s 832us/step - loss: 5.2143e-04 - accuracy: 0.9874\n",
      "63/63 [==============================] - 0s 650us/step - loss: 6.9848e-04 - accuracy: 0.9875\n",
      "Test Loss: 0.0006984805222600698\n",
      "Test Accuracy 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "#Create the layers\n",
    "inputs = keras.Input(shape=(3,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(6, best_hps = tuner.get_best_hyperparameters(num_trials=1)[0], activation=\"relu\")(x)\n",
    "#x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(2)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"model\")\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=20)\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Test Accuracy\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a94c6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9244 - val_loss: 5.9190e-04 - val_accuracy: 0.9844\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7522e-04 - accuracy: 0.9909 - val_loss: 5.6951e-04 - val_accuracy: 0.9956\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7666e-04 - accuracy: 0.9906 - val_loss: 5.6731e-04 - val_accuracy: 0.9919\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7832e-04 - accuracy: 0.9898 - val_loss: 5.6391e-04 - val_accuracy: 0.9887\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7872e-04 - accuracy: 0.9905 - val_loss: 5.7366e-04 - val_accuracy: 0.9919\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8723e-04 - accuracy: 0.9878 - val_loss: 5.6851e-04 - val_accuracy: 0.9887\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8582e-04 - accuracy: 0.9887 - val_loss: 5.9064e-04 - val_accuracy: 0.9944\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9478e-04 - accuracy: 0.9883 - val_loss: 6.0413e-04 - val_accuracy: 0.9906\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8433e-04 - accuracy: 0.9897 - val_loss: 5.8197e-04 - val_accuracy: 0.9881\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7817e-04 - accuracy: 0.9892 - val_loss: 6.3450e-04 - val_accuracy: 0.9737\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.0354e-04 - accuracy: 0.9887 - val_loss: 6.2026e-04 - val_accuracy: 0.9956\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9229e-04 - accuracy: 0.9891 - val_loss: 6.4004e-04 - val_accuracy: 0.9919\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8290e-04 - accuracy: 0.9903 - val_loss: 5.8610e-04 - val_accuracy: 0.9925\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9866e-04 - accuracy: 0.9881 - val_loss: 5.8527e-04 - val_accuracy: 0.9837\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9935e-04 - accuracy: 0.9887 - val_loss: 6.1668e-04 - val_accuracy: 0.9937\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 4.9864e-04 - accuracy: 0.9889 - val_loss: 5.7896e-04 - val_accuracy: 0.9894\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9224e-04 - accuracy: 0.9895 - val_loss: 5.7204e-04 - val_accuracy: 0.9944\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 4.9512e-04 - accuracy: 0.9883 - val_loss: 5.8247e-04 - val_accuracy: 0.9881\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7956e-04 - accuracy: 0.9900 - val_loss: 5.6291e-04 - val_accuracy: 0.9919\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9169e-04 - accuracy: 0.9881 - val_loss: 6.0250e-04 - val_accuracy: 0.9925\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.0693e-04 - accuracy: 0.9875 - val_loss: 5.6876e-04 - val_accuracy: 0.9931\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 5.0111e-04 - accuracy: 0.9889 - val_loss: 5.9058e-04 - val_accuracy: 0.9800\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.0495e-04 - accuracy: 0.9891 - val_loss: 6.1081e-04 - val_accuracy: 0.9794\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8529e-04 - accuracy: 0.9886 - val_loss: 6.1077e-04 - val_accuracy: 0.9887\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8928e-04 - accuracy: 0.9892 - val_loss: 6.5109e-04 - val_accuracy: 0.9806\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9080e-04 - accuracy: 0.9878 - val_loss: 5.6499e-04 - val_accuracy: 0.9950\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9383e-04 - accuracy: 0.9902 - val_loss: 5.8268e-04 - val_accuracy: 0.9806\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8522e-04 - accuracy: 0.9886 - val_loss: 5.9786e-04 - val_accuracy: 0.9800\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.8597e-04 - accuracy: 0.9883 - val_loss: 5.7718e-04 - val_accuracy: 0.9950\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9536e-04 - accuracy: 0.9884 - val_loss: 5.7890e-04 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be9a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
